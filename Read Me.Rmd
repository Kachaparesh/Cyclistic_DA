---
title: "Cyclistic riders' beahviour"
author: "Paresh"
date: "03/05/2021"
output: html_document
---

# ASK Phase

* Case study to study trends of annual and casual riders' behavior at Cyclistic.
* Aim of this analysis, to share findings with stakeholders to increase users with annual subscription.
* Data provided by, by Motivate International Inc. under this [liecense](https://www.divvybikes.com/data-license-agreement).

## Stakeholders

* Cyclistic
* Manager/Director of marketing
* Cyclistic marketing analytics team
* Cyclistic executive team

# Prepare Phase

### Where is your data located?
12 Month data is available in CSV format by online directory access

### How is the data organized?
Data is organized in such a way that we can create metrics in timely manner and store wise as well, this both dimensions are useful and with unique records with date-time and store id, it also include Latitude and Longitude so distance measurement is also available.

### Are there issues with bias or credibility in this data? Does your data ROCCC?

R - Reliable        -> Since data is from trusted sources and protected under license for restricted analysis use, we can consider it reliable.

O - Original        -> This data is provided by company itself with its own mechanism of identifying the store and managing uniqueness of records we can consider it as an original records.

C - Comprehensive   -> Because we are focusing here to analyze the behavior data is explanatory to analyze several dimensions.

C - Current         -> Time range for analysis is latest.

C - Cited           -> Please check citation in ASK phase.

### How are you addressing licensing, privacy, security, and accessibility?
    
Under **licensing** this analysis only presents overall behavior of users, based on their membership.
    
While performing and sharing my analysis, My moral duty will be  protect any potential information that can disclose user's identity.
    
### How did you verify the data’s integrity?

Data integrity can be confirmed by uniqueness of record kept within CSV files, More over for file integrity hash code can be matched.

### How does it help you answer your question?
Analyzing user's usage trend of the service supposed to be performed with comparison between annual subscribed member and casual member. For this analysis we will consider three dimensions to present our metrics.

Trend against Time
    
Trend against Store (Location)

Trend against distance (distance of ride)
    
### Are there any problems with the data?
After checking missing data values, several empty records found which are available without ending trip details such as end store and lat & long. And many of the records doesn't have valid time duration (zero or even less then zero time difference between ended_at and started_at)

# Process Phase

### What tools are you choosing and why?
The records are well organized in monthly time sheets yet they are very huge to handle with excel sheet, hence I am going to use RStudio to gain my skills in data cleaning with R, and creating visualization is easy and faster with tableau so I am going to use that.

### Have you ensured your data integrity?
The source of data for this case study is legitimate as we have seen the licensing under which the data is protected. Now we will check the data structure under arrangements of records to ensure we can trust the data recorded are uniform and validated. 

### What steps have you taken to ensure that your data is clean?
Check if data is validate throughout the data set. To do that following steps will be performed.
    
Create data frame from first month of records from csv file.
    
```{r Data Migration and quick information, message=FALSE, warning=FALSE}

# Data cleaning library
library(dplyr)

# Package to calculate geo distance 
library(radiant)

# Get all csv files from the directory
setwd("C:\\Users\\Paresh\\Documents\\Cyclistic\\Cyclistic_DA\\DataSets\\")

#  Store file name in variable for easy access
file <- "202004-divvy-tripdata"
fileExtension <- "csv"
fileName <- paste(file, fileExtension, sep = ".")
print(fileName)

#  Read CSV files and store data in data frame
# trip_data <- ldply(list.files(), read.csv, header=TRUE)
trip_data <- read.csv(fileName)

# Get quick details about data frame
str(trip_data)
```
    
From execution of above code chunk, we can see there are total 84776 records with 13 columns
    
```{r Check for uniqueness of records by checking duplicate Ride Id}
trip_data %>% 
  group_by(ride_id) %>% 
  mutate(duplicate_name = n()-1) %>% 
  ungroup() %>% 
  filter(duplicate_name > 0)
```
    
Above code snippet confirms that all the records are unique and available for analysis.
    
```{r filter missing data, and check ratio}

# 1) total number of record in the data frame
total_records <- nrow(trip_data)

# 2) Get records without missing value
records_without_missing_values <- trip_data[complete.cases(trip_data), ]

# 3) filter records further to check validation: positive time duration and time is not more then a day

records_without_missing_values$ride_duration <- as.numeric(difftime(strptime(records_without_missing_values$ended_at, "%Y-%m-%d %H:%M:%S", tz = "GMT"), strptime(records_without_missing_values$started_at, "%Y-%m-%d %H:%M:%S", tz = "GMT"), units = "secs"))
  
records_with_valid_values <- filter(records_without_missing_values, ride_duration > 0)


# 4) Get week day of start and end times for further analysis
records_with_valid_values$start_day <- weekdays(as.Date(records_with_valid_values$started_at))
records_with_valid_values$end_day <- weekdays(as.Date(records_with_valid_values$ended_at))

# 5) Insert new row with distance in meter
records_with_valid_values$ride_distance_in_meter <- as.numeric(
    as_distance(
      records_with_valid_values$start_lat, records_with_valid_values$start_lng, records_with_valid_values$end_lat, records_with_valid_values$end_lng, unit = "km"
      ) * 1000
    )

# 6) To check avg speed of ride in meter/second, to filter bias and consider riders who has actually ride the bike
records_with_valid_values$ride_avg_speed <- records_with_valid_values$ride_distance_in_meter/as.numeric(records_with_valid_values$ride_duration)

records_with_valid_values <- records_with_valid_values %>% filter(ride_avg_speed > 0)

# Count total valid records
count_of_valid_records <- nrow(records_with_valid_values)

# 7) check if 80% of data qualifies for the analysis
ratio_of_valid_records <- (count_of_valid_records/total_records)*100
print(ratio_of_valid_records)
```
    
Above code filter records with missing values, invalid values and biased records.
    
Here we can notice that many records doesn't have any information about ending the rides. This can by analyzed as a **Gap** in either flow, logic, or in development. But for now sticking to our goal. Since we need to study trend between annual users and casual users these records with missing value affects our analysis if we visualize data against traveled distance. So we will get rid of these data.
    
    
### How can you verify that your data is clean and ready to analyze?

After performing above operations, we can confirm that in resulting data frame there is no such records which might diverse our analysis. But to align our analysis with business goal we need some more insights from available data. We will achieve these by calculating **duration of rides**, **week day of ride** and **total distance of the ride**.

To deal with records that have missing or invalid values, we can find a ratio between records with complete value and records with missing/invalid value, and if this ratio is negligible for example around 20% of total records, then we can remove such records and it improves confident level of analysis in right direction.

Process to filter records with missing values

- Remove records with NA values

Process to filter records with invalid values

- Remove record that have time duration less than zero, and greater than a day (Check 3rd code chunk in above snippet)

Process to filter records with biased data

- Here even though there are records with complete ride details, there are many records were user hasn't even ride the cycle. Such records might affect our analysis at this stage, So, filter such records were necessary. (Check 6th code chunk)

### Have you documented your cleaning process so you can review and share those results?

Yes cleaning process is divided in 3 parts and each of them are documented above, with necessary code its reasoning and more explanation.

This cleaning process is performed on data sheet of one month, and it can be automated for other data sheets.

Now the data is ready to analyze the trend against week days, ride distance and hourly basis.


# Analyze Phase

### How should you organize your data to perform analysis on it?

To use above validated records later for analysis, I am going to write every frame in its relative csv file format, which will be created new at different location.
```{r csv file creation with new name and location}

# New file name using old one
newFileName <- paste(paste(file, "-validated", sep = ""), fileExtension, sep = ".") 
write.csv(records_with_valid_values, newFileName)
```


### Has your data been properly formatted?

Data is rectified with 3 different processes and stored in newly created CSV files for later use without affecting original data.

### What surprises did you discover in the data?

Findings

- Many records don't have information about ending ride.

- Some records have invalid start and end time of the ride, which means started_at has a greater value then ended_at.

- After checking a total duration of rides in minutes, some entries found which has very huge time duration, which is even more than a year in some cases.

- I tried to find a distance of a ride from latitude and longitude of the ride, to check total travel distance and this data has bias as well.

- After applying simple equation of finding user speed, I cam to know that there are some records with very high speed in meter/seconds. Which is simply not possible for electrical cycle.

- After above findings, I have removed obvious data only, with missing values and will continue my analysis, and by time i will try to make it more precise.

### What trends or relationships did you find in the data?

### How will these insights help answer your business questions?


# Share Phase

● Were you able to answer the question of how annual members and casual riders use Cyclistic bikes differently?
● What story does your data tell?
● How do your findings relate to your original question?
● Who is your audience? What is the best way to communicate with them?
● Can data visualization help you share your findings?
● Is your presentation accessible to your audience?

# Act Phase

● What is your final conclusion based on your analysis?
● How could your team and business apply your insights?
● What next steps would you or your stakeholders take based on your findings?
● Is there additional data you could use to expand on your findings?

# **Currently working**