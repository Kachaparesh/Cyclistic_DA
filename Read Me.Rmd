---
title: "Cyclistic riders' beahviour"
author: "Paresh"
date: "03/05/2021"
output: html_document
---

# ASK Phase

* Case study to study trends of annual and casual riders' behavior at Cyclistic.
* Aim of this analysis, to share findings with stakeholders to increase users with annual subscription.
* [Data](https://divvy-tripdata.s3.amazonaws.com/index.html) provided by, by Motivate International Inc. under this [liecense](https://www.divvybikes.com/data-license-agreement).

## Stakeholders

* Manager/Director of marketing
* Cyclistic marketing analytics team
* Cyclistic executive team

# Prepare Phase

### Where is your data located?
13 Month data is available in CSV format by online directory access

### How is the data organized?
Data is organized in such a way that we can create metrics in timely manner and store wise as well, this both dimensions are useful and with unique records with date-time and store id, it also include Latitude and Longitude so distance measurement is also available.

### Are there issues with bias or credibility in this data? Does your data ROCCC?

R - Reliable        -> Since data is from trusted sources and protected under license for restricted analysis use, we can consider it reliable.

O - Original        -> This data is provided by company itself with its own mechanism of identifying the store and managing uniqueness of records we can consider it as an original records.

C - Comprehensive   -> Because we are focusing here to analyze the behavior data is explanatory to analyze several dimensions.

C - Current         -> Time range for analysis is latest.

C - Cited           -> Please check citation in ASK phase.

### How are you addressing licensing, privacy, security, and accessibility?
    
Under **licensing** this analysis only presents overall behavior of users, based on their membership.
    
While performing and sharing my analysis, My moral duty will be  protect any potential information that can disclose user's identity.
    
### How did you verify the dataâ€™s integrity?

Data integrity can be confirmed by uniqueness of record kept within CSV files, More over for file integrity hash code can be matched.

### How does it help you answer your question?
Analyzing user's usage trend of the service supposed to be performed with comparison between annual subscribed member and casual member. For this analysis we will consider three dimensions to present our metrics.

Trend against Time
    
Trend against Store (Location)

Trend against distance (distance of ride)
    
### Are there any problems with the data?
After checking missing data values, several empty records found which are available without ending trip details such as end store and lat & long. And many of the records doesn't have valid time duration (zero or even less then zero time difference between ended_at and started_at)

# Process Phase

### What tools are you choosing and why?
The records are well organized in monthly time sheets yet they are very huge to handle with excel sheet, hence I am going to use RStudio to gain my skills in data cleaning with R, and creating visualization is easy and faster with tableau so I am going to use that.

### Have you ensured your data integrity?
The source of data for this case study is legitimate as we have seen the licensing under which the data is protected. Now we will check the data structure under arrangements of records to ensure we can trust the data recorded are uniform and validated. 

### What steps have you taken to ensure that your data is clean?
Check if data is validate throughout the data set. To do that following steps will be performed.
    
Create data frame from first month of records from csv file.
    
```{r Data Migration and quick information, message=FALSE, warning=FALSE}

# Data cleaning library
library(dplyr)

# Package to calculate geo distance 
library(radiant)

# Data visualization library
library(ggplot2)
library(gridExtra)

# Get all csv files from the directory
setwd("C:\\Users\\Paresh\\Documents\\Cyclistic\\Cyclistic_DA\\DataSets\\")

#  Store file name in variable for easy access
file <- "202004-divvy-tripdata"
fileExtension <- "csv"
fileName <- paste(file, fileExtension, sep = ".")
print(fileName)

#  Read CSV files and store data in data frame
# trip_data <- ldply(list.files(), read.csv, header=TRUE)
trip_data <- read.csv(fileName)

# Get quick details about data frame
str(trip_data)
```
    
From execution of above code chunk, we can see records with 13 columns
    
```{r Check for uniqueness of records by checking duplicate Ride Id}
trip_data %>% 
  group_by(ride_id) %>% 
  mutate(duplicate_name = n()-1) %>% 
  ungroup() %>% 
  filter(duplicate_name > 0)
```
    
Above code snippet confirms that all the records are unique and available for analysis.
    
```{r filter missing data, and check ratio}
# 1) total number of record in the data frame
  total_records <- nrow(trip_data)
  
  # 2) Get records without missing value
  records_without_missing_ending_trip_data <- trip_data[!apply(trip_data, 1, function(x) any(x=="")),] 

  # 3) filter records further to check validation: positive time duration where time is not more then a day
  ride_duration_in_secs <- as.numeric(difftime(strptime(records_without_missing_ending_trip_data$ended_at, "%Y-%m-%d %H:%M:%S", tz = "GMT"), strptime(records_without_missing_ending_trip_data$started_at, "%Y-%m-%d %H:%M:%S", tz = "GMT"), units = "secs"))
  records_without_missing_ending_trip_data$ride_duration_in_secs <- round(ride_duration_in_secs, 2)
  
  records_with_valid_ride_duration <- filter(records_without_missing_ending_trip_data, ride_duration_in_secs > 0)
  
  # 4.1) Get week day of start and end times for further analysis
  records_with_valid_ride_duration$start_day <- weekdays(as.Date(records_with_valid_ride_duration$started_at))
  records_with_valid_ride_duration$end_day <- weekdays(as.Date(records_with_valid_ride_duration$ended_at))
  
  # 4.2) Get month of start and end times for further analysis
  records_with_valid_ride_duration$start_ride_month <- months(as.Date(records_with_valid_ride_duration$started_at))
  records_with_valid_ride_duration$end_ride_month <- months(as.Date(records_with_valid_ride_duration$ended_at))
  
  # 4.3) Get hour and date of start times for further analysis
  records_with_valid_ride_duration$start_ride_hour <- hour(records_with_valid_ride_duration$started_at)
  records_with_valid_ride_duration$start_ride_date <- date(records_with_valid_ride_duration$started_at)
  
  # 5) Insert new row with distance in meter
  records_with_valid_ride_duration$ride_distance_in_meter <- round(
    as_distance(
      records_with_valid_ride_duration$start_lat, records_with_valid_ride_duration$start_lng, records_with_valid_ride_duration$end_lat, records_with_valid_ride_duration$end_lng, unit = "km"
    ) * 1000
    , 2)
  
  # 5.1) filter rows that shows no ride distance
  records_with_valid_ride_duration <- records_with_valid_ride_duration %>% filter(ride_distance_in_meter > 0)
  
  records_with_valid_distance <- nrow(records_with_valid_ride_duration)
  
  # 6) To check avg speed of ride in meter/second, to filter bias and consider riders who has actually ride the bike
  records_with_valid_ride_duration$ride_avg_speed_in_meter_per_sec <- round(records_with_valid_ride_duration$ride_distance_in_meter/as.numeric(records_with_valid_ride_duration$ride_duration), 2)
  
  records_with_valid_ride_duration <- records_with_valid_ride_duration %>% filter(ride_avg_speed_in_meter_per_sec < 20)
  
  # Count total valid records
  count_of_valid_records <- nrow(records_with_valid_ride_duration)
  
  # 7) check if 80% of data qualifies for the analysis
  ratio_of_valid_records <- (count_of_valid_records/total_records)*100
  print(ratio_of_valid_records)
  
  # data analysis for quality
 data_quality_metrics <- c(total_records, nrow(records_without_missing_ending_trip_data), records_with_valid_distance, count_of_valid_records)
 print(data_quality_metrics)
```
    
Above code filter records with missing values, invalid values and biased records.
    
Here we can notice that many records doesn't have any information about ending the rides. This can by analyzed as a **Gap** in either flow, logic, or in development. But for now sticking to our goal. Since we need to study trend between annual users and casual users these records with missing value affects our analysis if we visualize data against traveled distance. So we will get rid of these data.
    
    
### How can you verify that your data is clean and ready to analyze?

After performing above operations, we can confirm that in resulting data frame there is no such records which might diverse our analysis. But to align our analysis with business goal we need some more insights from available data. We will achieve these by calculating **duration of rides**, **week day of ride** and **total distance of the ride**.

To deal with records that have missing or invalid values, we can find a ratio between records with complete value and records with missing/invalid value, and if this ratio is negligible for example around 20% of total records, then we can remove such records and it improves confident level of analysis in right direction.

Process to filter records with missing values

- Remove records with NA values

Process to filter records with invalid values

- Remove record that have time duration less than zero, and greater than a day (Check 3rd code chunk in above snippet)

Process to filter records with biased data

- Here even though there are records with complete ride details, there are many records were user hasn't even ride the cycle. Such records might affect our analysis at this stage, So, filter such records were necessary. (Check 6th code chunk)

### Have you documented your cleaning process so you can review and share those results?

Yes cleaning process is divided in 3 parts and each of them are documented above, with necessary code, its reasoning and more explanation.

This cleaning process is performed on data sheet of one month, and it can be automated for other data sheets.

Now the data is ready to analyze the trend against week days, ride distance and hourly basis.


# Analyze Phase

### How should you organize your data to perform analysis on it?

To use above validated records later for analysis, I am going to write every frame in its relative csv file format, which will be created at different location.


### Has your data been properly formatted?

Data is rectified with 3 different processes and stored in newly created CSV files for later use without affecting original data.

More on that, I have performed single file operation which is automated later on for every file with forloop.

### What surprises did you discover in the data?

Findings

- Many records don't have information about ending ride.

- Some records have invalid start and end time of the ride, which means started_at has a greater value then ended_at.

- After checking a total duration of rides in minutes, some entries found which has very huge time duration, which is even more than a year in some cases.

- I tried to find a distance of a ride from latitude and longitude of the ride, to check total travel distance and this data has bias as well.

- After applying simple equation of finding user speed, I cam to know that there are some records with very high speed in meter/seconds. Which is simply not possible for electrical cycle.

- After above findings, I have removed obvious data only, with missing values and will continue my analysis, and by time i will try to make it more precise.

### What trends or relationships did you find in the data?

- After performing EDA i came to know that, annual members use E-Cycle with peace of mind, and more frequently. Where casual members use E-Cycle more then annual members in terms of duration and distance, which means casual members rush their commute.

### How will these insights help answer your business questions?
- This findings will help stakeholders to find a gap, how to overcome and use it for a marketing strategy. For example casual user do enjoy rides, but they rush their riding which means they don't want to tie themselves in pricing criteria and want to use this services within short time span. So possible solution might be to offer monthly subscription along with annual subscription.

# Share Phase

### Were you able to answer the question of how annual members and casual riders use Cyclistic bikes differently?

- Casual members do enjoy riding bikes, but they don't want to get tied in annual subscription. In result they rush their commute as they are paying as per their ride distance i guess. Where annual member use bikes with peace of mind and more frequently than casual users.

### What story does your data tell?
```{r}
# Usage analysis per week day
 plotPrep <- records_with_valid_ride_duration %>% 
   group_by(start_day, member_casual, start_ride_month) %>% 
   dplyr :: summarise(count = n(), usage = sum(ride_distance_in_meter), duration = sum(ride_duration_in_secs))

p1 <- ggplot(data = plotPrep) +
 geom_col(position = "dodge", mapping = aes(x=start_day, y=duration, fill = member_casual)) +
   theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1,size=7)) +
  labs( x = "Day of the week", y = "Total time spent in seconds ",
        title ="Time spent by user every week day") +
   facet_wrap(~start_ride_month)
 
p2 <- ggplot(data = plotPrep) +
   geom_col(position = "dodge", mapping = aes(x=start_day, y=usage, fill = member_casual)) +
   theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1,size=7)) +
  labs( x = "Day of the week", y = "Total distnace in meter ",
        title ="Distance of rides every week day") + 
  facet_wrap(~start_ride_month)

grid.arrange(p1, p2, nrow = 1)
```

- After quick visualization with ggplot2 in RSTudio, I decided to dig further with Tableau.After preparing a dashboard and playing with it i realized that annual member use bikes with peace of mind, more frequently even for shorter distance. Where casual members really push the limits while riding the bike. I was able conclude this part by finding speed of rides.

### How do your findings relate to your original question?
- Finding annual and casual user behavior was the aim of this analysis, and i was able to achieve that by comparing data at different stages.which includes find ride distance from start and end latitude and longitudes. and time spend per ride. Which has eventually given me a speed per ride where actual behaviour is revealed.

### Who is your audience? What is the best way to communicate with them?
* Manager/Director of marketing
* Cyclistic marketing analytics team
* Cyclistic executive team
* Other colleague 

### Can data visualization help you share your findings?
Yes I have made a quick visualization for meeting where executives can take a look quickly. More on that, I have created a detailed dashboard with tableau where other team members from marketing team and managers can interact with suitable depth of analysis.


### Is your presentation accessible to your audience?
I have shared this presentation with a public link, since that is the only option with [tableau public](https://public.tableau.com/views/CyclisticEDA/CyclisiticVisualization?:language=en&:display_count=y&:origin=viz_share_link).


# Act Phase

### What is your final conclusion based on your analysis?
- User enjoy riding Cyclisitic bikes regardless of subscription but usage are different because of memberships. Casual users try to use bikes with maximum limit to finish their ride in time, where annual members use it more frequently without worrying of time and cost.

### How could your team and business apply your insights?
- Casual members' usage are restricted to time and cost, so if team decide to announce new monthly subscription, user behavior about rides might change. Which can be reveal in dashboard.

### What next steps would you or your stakeholders take based on your findings?
- They will be able to use any of the aspects I have highlighted here for the marketing, or performing research for new kind subscriptions.


### Is there additional data you could use to expand on your findings?

- Yes, two things I noticed.

1) Previous data is available which we can use to predict usage.

2) If i can get this data in a form of json, i can update dashboard live.
# **Currently working**